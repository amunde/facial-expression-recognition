{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Expression Recognition Dataset overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is using the dataset from the Kaggle competition (https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/leaderboard). The data consists of 48x48 pixel grayscale images of faces. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN Architecture has been used to predict the facial expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dict = { }\n",
    "\n",
    "class_number = 0\n",
    "\n",
    "data = []\n",
    "\n",
    "labels = []\n",
    "\n",
    "# Extracting file names into a dictionary \n",
    "for i in range(7): \n",
    "    \n",
    "    data_dict[\"class_\" + str(i)] = os.listdir('Training/'+str(i))\n",
    "    \n",
    "\n",
    "# Converting the images into array (input) and label (outputs) \n",
    "for emotion_class,img_names in data_dict.items():\n",
    "    \n",
    "    for img in img_names:\n",
    "        \n",
    "        img_read = plt.imread('Training/'+ str(class_number) +  '/' + img)\n",
    "        img_resize = cv2.resize(img_read, (48, 48)) # Converting image to (48, 48)\n",
    "        img_array = img_to_array(img_resize) # Converting to array\n",
    "        data.append(img_array)\n",
    "        labels.append(class_number)\n",
    "        \n",
    "    class_number = class_number+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = np.array(data)\n",
    "\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the data\n",
    "idx = np.arange(image_data.shape[0])\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "image_data = image_data[idx]\n",
    "\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into testing and training sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_data, labels, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, num_classes = 7)\n",
    "\n",
    "y_test = np_utils.to_categorical(y_test, num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a model\n",
    "\n",
    "def CNNbuild(height, width, classes, channels):\n",
    "    model = Sequential()\n",
    "    \n",
    "    inputShape = (height, width, channels)\n",
    "    chanDim = -1\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        inputShape = (channels, height, width)\n",
    "    model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = inputShape))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(128, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Conv2D(256, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, activation = 'relu'))\n",
    "    model.add(BatchNormalization(axis = chanDim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 23, 23, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 4,578,055\n",
      "Trainable params: 4,575,111\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "height = 48 # Resized image size (48, 48)\n",
    "width = 48\n",
    "classes = 7 # 7 output classes\n",
    "channels = 1 # Monochrome images so single channel \n",
    "model = CNNbuild(height = height, width = width, classes = classes, channels = channels)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22966/22966 [==============================] - 519s 23ms/step - loss: 2.1035 - acc: 0.3160\n",
      "Epoch 2/10\n",
      "22966/22966 [==============================] - 551s 24ms/step - loss: 1.5926 - acc: 0.4182\n",
      "Epoch 3/10\n",
      "22966/22966 [==============================] - 638s 28ms/step - loss: 1.4568 - acc: 0.4540\n",
      "Epoch 4/10\n",
      "22966/22966 [==============================] - 680s 30ms/step - loss: 1.3718 - acc: 0.4820\n",
      "Epoch 5/10\n",
      "22966/22966 [==============================] - 636s 28ms/step - loss: 1.3188 - acc: 0.5073\n",
      "Epoch 6/10\n",
      "22966/22966 [==============================] - 572s 25ms/step - loss: 1.2706 - acc: 0.5233\n",
      "Epoch 7/10\n",
      "22966/22966 [==============================] - 585s 25ms/step - loss: 1.2235 - acc: 0.5371\n",
      "Epoch 8/10\n",
      "22966/22966 [==============================] - 583s 25ms/step - loss: 1.1911 - acc: 0.5504\n",
      "Epoch 9/10\n",
      "22966/22966 [==============================] - 639s 28ms/step - loss: 1.1522 - acc: 0.5671\n",
      "Epoch 10/10\n",
      "22966/22966 [==============================] - 697s 30ms/step - loss: 1.1233 - acc: 0.5788\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(x_train, y_train, epochs = 10, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5742/5742 [==============================] - 25s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS : 1.1467532117123473\n",
      "ACCURACY : 0.5689655173036621\n"
     ]
    }
   ],
   "source": [
    "print(f'LOSS : {predictions[0]}')\n",
    "print(f'ACCURACY : {predictions[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Output\n",
    "\n",
    "\n",
    "EPOCS : 10\n",
    "\n",
    "LOSS : 1.1467532117123473\n",
    "\n",
    "TESTING ACCURACY : 0.5689655173036621\n",
    "\n",
    "TRAINING ACCURACY : 0.5788\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
